name: Production Pipeline (Build, Copy & Deploy)

on:
  push:
    branches: [ "production" ]

jobs:
  # ====================================================
  # JOB 1: CHECK DE QUALIDADE (TESTES)
  # ====================================================
  quality-check:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: studyflow_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: password
        ports:
          - 5432:5432
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r backend/requirements.txt

      - name: Run Tests
        env:
          SECRET_KEY: 'test-key-safe'
          DEBUG: '1'
          DB_HOST: localhost
          DB_PORT: 5432
          POSTGRES_DB: studyflow_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: password
          REDIS_HOST: localhost
          GEMINI_API_KEY: 'dummy-key'
        run: |
          cd backend
          python manage.py test

  # ====================================================
  # JOB 2: DEPLOY COMPLETO (DOCKER + NGINX + ENV)
  # ====================================================
  deploy:
    needs: quality-check
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Login Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      # 1. BUILD DO BACKEND (DOCKER)
      - name: Build & Push Backend
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: true
          tags: ${{ secrets.DOCKER_IMAGE }}:latest

      # 2. COPIA DE ARQUIVOS (NGINX & COMPOSE)
      # Isso garante que a pasta 'nginx' e o arquivo 'docker-compose.prod.yml' existam no servidor
      - name: Copy Config Files to EC2
        uses: appleboy/scp-action@master
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          source: "docker-compose.prod.yml,nginx"
          target: "/home/${{ secrets.EC2_USER }}/studyflow"

      # 3. GERAÇÃO DO ENV E START
      - name: Deploy on EC2
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            cd /home/${{ secrets.EC2_USER }}/studyflow
            
            # --- CRIAÇÃO DO ARQUIVO .ENV (DINÂMICO) ---
            echo "Gerando .env de produção..."
            echo "DEBUG=0" > .env
            echo "SECRET_KEY=${{ secrets.DJANGO_SECRET_KEY }}" >> .env
            echo "ALLOWED_HOSTS=${{ secrets.ALLOWED_HOSTS }}" >> .env
            echo "POSTGRES_DB=${{ secrets.POSTGRES_DB }}" >> .env
            echo "POSTGRES_USER=${{ secrets.POSTGRES_USER }}" >> .env
            echo "POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}" >> .env
            echo "DB_HOST=db" >> .env
            echo "DB_PORT=5432" >> .env
            echo "DOCKER_IMAGE=${{ secrets.DOCKER_IMAGE }}:latest" >> .env
            echo "REDIS_HOST=redis" >> .env
            echo "RABBITMQ_DEFAULT_USER=${{ secrets.RABBITMQ_USER }}" >> .env
            echo "RABBITMQ_DEFAULT_PASS=${{ secrets.RABBITMQ_PASS }}" >> .env
            echo "GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }}" >> .env
            echo "GOOGLE_CLIENT_ID=${{ secrets.GOOGLE_CLIENT_ID }}" >> .env
            echo "GOOGLE_CLIENT_SECRET=${{ secrets.GOOGLE_CLIENT_SECRET }}" >> .env

            # Login no Docker Hub dentro do servidor
            echo "${{ secrets.DOCKERHUB_TOKEN }}" | docker login -u "${{ secrets.DOCKERHUB_USERNAME }}" --password-stdin
            
            # Atualiza as imagens
            docker compose -f docker-compose.prod.yml pull web
            
            # Sobe os containers (Recria o web e nginx se necessário)
            docker compose -f docker-compose.prod.yml up -d --remove-orphans
            
            # Comandos de manutenção do Django
            echo "Rodando migrations..."
            docker compose -f docker-compose.prod.yml exec -T web python manage.py migrate --noinput
            
            echo "Coletando estáticos..."
            docker compose -f docker-compose.prod.yml exec -T web python manage.py collectstatic --noinput
            
            # Limpeza de disco
            docker image prune -f