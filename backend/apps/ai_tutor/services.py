import os
import json
import google.generativeai as genai
from django.conf import settings
from .models import TopicCache 

class AIService:
    def __init__(self):
        api_key = os.environ.get("GEMINI_API_KEY")
        if api_key:
            genai.configure(api_key=api_key)
            self.is_configured = True
        else:
            self.is_configured = False

    def get_pedagogical_answer(self, question: str, subject: str = "Geral") -> str:
        """
        Retorna uma resposta socr√°tica para o chat (String simples).
        """
        if not self.is_configured: return "Erro: API Key n√£o configurada."
        try:
            model = genai.GenerativeModel("gemini-2.0-flash", system_instruction="Tutor Socr√°tico. Ajude o aluno a pensar.")
            response = model.generate_content(f"{subject}: {question}")
            return response.text
        except Exception as e: return f"Erro IA: {str(e)}"

    def analyze_topic(self, topic: str, depth: str = "initial") -> dict:
        """
        Gera an√°lise estruturada com estrat√©gia Cache-Aside.
        Suporta depths: 'initial', 'deep', 'patterns', 'troubleshooting'
        """
        clean_topic = topic.strip().lower()
        # A chave de cache inclui o 'depth' para diferenciar os tipos de conte√∫do
        cache_key = f"{clean_topic}_{depth}"

        print(f"üîç Buscando cache para: {clean_topic} (N√≠vel: {depth})")
        
        # 1. Tenta buscar no banco local
        cached_entry = TopicCache.objects.filter(topic=clean_topic, depth=depth).first()
        
        if cached_entry:
            print("‚ö° CACHE HIT: Retornando dados do banco local.")
            return cached_entry.data

        # 2. Se n√£o achar, consulta a IA
        print("ü§ñ CACHE MISS: Consultando Gemini IA...")
        
        if not self.is_configured:
            return {"error": "IA n√£o configurada"}

        # ====================================================
        # ‚öôÔ∏è CONFIGURA√á√ÉO DIN√ÇMICA DE PROMPTS E SCHEMAS
        # ====================================================
        configs = {
            "initial": {
                "prompt": f"Analise o termo t√©cnico: '{topic}'. Responda em Portugu√™s do Brasil com foco em fundamentos.",
                "schema": {
                    "type": "object",
                    "properties": {
                        "definition": {"type": "string"},
                        "origin": {"type": "string"},
                        "pain_point": {"type": "string"},
                        "when_to_use": {"type": "string"},
                        "when_not_to_use": {"type": "string"},
                    },
                    "required": ["definition", "origin", "pain_point", "when_to_use", "when_not_to_use"]
                }
            },
            # Deep: Edge Cases e Detalhes Internos
            "deep": { 
                "prompt": f"Aprofunde no termo: '{topic}'. Foque em casos raros (edge cases) e limita√ß√µes t√©cnicas. Portugu√™s BR.",
                "schema": {
                    "type": "object",
                    "properties": {
                        "edge_cases": {"type": "string", "description": "Situa√ß√µes extremas onde a tecnologia falha ou se comporta de forma inesperada"},
                        "advanced_detail": {"type": "string", "description": "Detalhe t√©cnico interno de como funciona 'por baixo do cap√¥'"},
                        "real_example": {"type": "string", "description": "Um cen√°rio do mundo real complexo"},
                    },
                    "required": ["edge_cases", "advanced_detail", "real_example"]
                }
            },
            # Patterns: Arquitetura e Padr√µes
            "patterns": {
                "prompt": f"Quais os Design Patterns e arquiteturas comuns associados a '{topic}'? Portugu√™s BR.",
                "schema": {
                    "type": "object",
                    "properties": {
                        "common_patterns": {"type": "string", "description": "Padr√µes de projeto comumente usados com essa tecnologia"},
                        "best_practices": {"type": "string", "description": "Boas pr√°ticas de arquitetura"},
                        "anti_patterns": {"type": "string", "description": "O que N√ÉO fazer (anti-padr√µes)"},
                    },
                    "required": ["common_patterns", "best_practices", "anti_patterns"]
                }
            },
            # Troubleshooting: Problemas do dia a dia
            "troubleshooting": {
                "prompt": f"Como Senior Engineer, liste os problemas mais comuns no dia a dia trabalhando com '{topic}' e como resolver. Portugu√™s BR.",
                "schema": {
                    "type": "object",
                    "properties": {
                        "common_bugs": {"type": "string", "description": "Erros frequentes que iniciantes cometem"},
                        "debugging_tips": {"type": "string", "description": "Dicas de como debugar problemas nisso"},
                        "performance_impact": {"type": "string", "description": "Impactos de performance comuns"},
                    },
                    "required": ["common_bugs", "debugging_tips", "performance_impact"]
                }
            }
        }

        # Seleciona a configura√ß√£o ou usa 'deep' como fallback seguro
        current_config = configs.get(depth, configs["deep"])

        try:
            generation_config = {
                "temperature": 0.4,
                "response_mime_type": "application/json",
                "response_schema": current_config["schema"]
            }

            model = genai.GenerativeModel(
                model_name="gemini-2.0-flash",
                system_instruction="Voc√™ √© um Arquiteto de Software S√™nior e Tutor T√©cnico.",
                generation_config=generation_config
            )
            
            response = model.generate_content(current_config["prompt"])
            json_data = json.loads(response.text)

            # 3. Salva no Cache
            print(f"üíæ Salvando {depth} no Cache...")
            TopicCache.objects.create(
                topic=clean_topic,
                depth=depth,
                data=json_data
            )
            
            return json_data

        except Exception as e:
            print(f"‚ùå ERRO AI SERVICES: {e}")
            return {"error": f"Falha na an√°lise: {str(e)}"}